# Setup Instructions for Intelligence Module

## ğŸ“ Estructura del MÃ³dulo

```
module-intelligence/
â”œâ”€â”€ app.py                          # FastAPI application
â”œâ”€â”€ Dockerfile                      # Docker image para Data Science
â”œâ”€â”€ requirements.txt                # Dependencias Python
â”œâ”€â”€ README.md                       # DocumentaciÃ³n principal
â”œâ”€â”€ MIGRATION.md                    # GuÃ­a de migraciÃ³n
â”œâ”€â”€ SETUP.md                        # Este archivo
â”œâ”€â”€ .gitignore                      # Git ignore
â”œâ”€â”€ .dockerignore                   # Docker ignore
â”œâ”€â”€ intelligence_service/           # CÃ³digo Python
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                       # MÃ³dulos core
â”‚   â”‚   â”œâ”€â”€ redis_client.py
â”‚   â”‚   â”œâ”€â”€ orion_client.py
â”‚   â”‚   â”œâ”€â”€ job_queue.py
â”‚   â”‚   â””â”€â”€ worker.py
â”‚   â””â”€â”€ plugins/                    # Plugins de anÃ¡lisis
â”‚       â”œâ”€â”€ base.py
â”‚       â””â”€â”€ simple_predictor.py
â””â”€â”€ k8s/                            # Manifests Kubernetes
    â”œâ”€â”€ deployment.yaml
    â””â”€â”€ ingress.yaml
```

## ğŸ“ Estructura del MÃ³dulo

```
module-intelligence/
â”œâ”€â”€ backend/                     # Backend FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI app factory
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration (pydantic-settings)
â”‚   â”‚   â”œâ”€â”€ api/                # API routes
â”‚   â”‚   â”œâ”€â”€ core/               # Core modules (jobs, worker, orion)
â”‚   â”‚   â”œâ”€â”€ plugins/            # Analysis plugins
â”‚   â”‚   â””â”€â”€ middleware/         # Auth middleware (optional)
â”‚   â”œâ”€â”€ tests/                  # Test suite
â”‚   â”œâ”€â”€ Dockerfile              # Multi-stage build for Data Science
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ k8s/                        # Kubernetes manifests
â”‚   â”œâ”€â”€ backend-deployment.yaml
â”‚   â””â”€â”€ registration.sql
â”œâ”€â”€ .github/workflows/          # CI/CD
â”‚   â””â”€â”€ build-push.yml
â”œâ”€â”€ manifest.json               # Module metadata for registration
â”œâ”€â”€ env.example                 # Environment template
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Pasos para Crear el Repositorio GitHub

### Paso 1: Revisar el contenido

```bash
cd module-intelligence/
ls -la
tree -L 3  # Ver estructura completa
```

### Paso 2: Crear repositorio en GitHub

1. Ve a https://github.com/k8-benetis
2. Click en "New repository"
3. Nombre: `nekazari-module-intelligence`
4. DescripciÃ³n: "Standalone AI/ML Intelligence Module for Nekazari Platform"
5. **NO** inicialices con README, .gitignore, o licencia (ya los tenemos)
6. Click "Create repository"

### Paso 3: Inicializar Git y hacer push

```bash
# Ya estÃ¡s en module-intelligence/
git init
git add .
git commit -m "feat: Initial commit - Intelligence Module v1.0

- Standalone FastAPI service for AI/ML analysis
- Redis-based async job queue
- Orion-LD integration for Prediction entities
- Plugin architecture for extensibility
- Kubernetes manifests included"

# Conectar con el repositorio remoto (reemplaza <repo-url> con la URL de GitHub)
git remote add origin https://github.com/k8-benetis/nekazari-module-intelligence.git

# Push inicial
git branch -M main
git push -u origin main
```

### Paso 4: Verificar

Ve a https://github.com/k8-benetis/nekazari-module-intelligence y verifica que todos los archivos estÃ©n presentes.

## ğŸ”§ ConfiguraciÃ³n Local (Testing)

### Instalar dependencias

```bash
cd module-intelligence/
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Variables de entorno

Crea un archivo `.env`:

```bash
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

ORION_URL=http://localhost:1026
CONTEXT_URL=https://nekazari.artotxiki.com/ngsi-ld-context.json

LOG_LEVEL=INFO
```

### Ejecutar localmente

```bash
uvicorn app:app --host 0.0.0.0 --port 8080 --reload
```

### Probar endpoints

```bash
# Health check
curl http://localhost:8080/health

# List plugins
curl http://localhost:8080/api/intelligence/plugins
```

## ğŸ³ Build Docker Image

```bash
# Build local
docker build -t nekazari-module-intelligence:latest .

# Test local
docker run -p 8080:8080 \
  -e REDIS_HOST=host.docker.internal \
  -e ORION_URL=http://host.docker.internal:1026 \
  nekazari-module-intelligence:latest
```

## ğŸ“¦ CI/CD Setup (Opcional)

Crea `.github/workflows/build.yml` en el nuevo repositorio:

```yaml
name: Build and Push Docker Image

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: ${{ github.event_name != 'pull_request' }}
          tags: ghcr.io/k8-benetis/nekazari-module-intelligence:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
```

## âœ… Checklist Final

- [ ] Repositorio creado en GitHub
- [ ] CÃ³digo pusheado
- [ ] README.md visible en GitHub
- [ ] Dockerfile presente
- [ ] Manifests K8s presentes
- [ ] CI/CD configurado (opcional)

## ğŸ”— PrÃ³ximos Pasos

1. **Desplegar en Kubernetes**: Usa los manifests en `k8s/`
2. **Integrar con Core**: El Core debe llamar a la API REST del mÃ³dulo
3. **AÃ±adir ML**: Descomenta librerÃ­as en `requirements.txt` cuando las necesites

## ğŸ“ Notas

- Este mÃ³dulo es **completamente independiente** del Core
- La Ãºnica comunicaciÃ³n es vÃ­a REST API y Orion-LD
- No hay dependencias compartidas
- EstÃ¡ preparado para escalar independientemente

